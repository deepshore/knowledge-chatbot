{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Vector Store\n",
    "\n",
    "- visualize high-dimensional data\n",
    "\n",
    "![](images/high-dimensional-data.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama_index\n",
    "#!pip install llama_hub --force-reinstall\n",
    "%pip uninstall -y llama_hub\n",
    "%pip install git+https://github.com/selamanse/llama-hub.git@add_extra_info_to_web\n",
    "%pip install langchain\n",
    "%pip install chromadb\n",
    "#!pip install git+https://github.com/mtybadger/chromaviz/\n",
    "%pip install -e /Users/selamanse/Documents/GITHUB/chromaviz"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import libraries and set api key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import sys\n",
    "import getpass\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "# using this to connect to openai\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"https://api.openai.com/v1\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data from website via sitemap\n",
    "\n",
    "using the [llama_hub loader for sitemaps](https://llama-hub-ui.vercel.app/l/web-sitemap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_hub.web.sitemap.base import SitemapReader\n",
    "\n",
    "# for jupyter notebooks uncomment the following two lines of code:\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "loader = SitemapReader(html_to_text=True)\n",
    "documents = loader.load_data(sitemap_url='https://deepshore.de/sitemap.xml', filter='https://deepshore.de/knowledge')\n",
    "\n",
    "print(len(documents))\n",
    "print(documents[0].extra_info)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add to Vector DB from Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from llama_index.schema import Document\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "#https://docs.trychroma.com/telemetry#opting-out\n",
    "chromadb_settings = Settings(anonymized_telemetry=False, persist_directory=\"./chroma\", chroma_db_impl=\"duckdb+parquet\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chromadb_client = chromadb.Client(chromadb_settings)\n",
    "chroma_client = Chroma(collection_name='deepshore-sitemap', client=chromadb_client, embedding_function=OpenAIEmbeddings())\n",
    "\n",
    "langchain_documents = []\n",
    "for d in documents:\n",
    "    langchain_documents.append(d.to_langchain_format())\n",
    "\n",
    "vectordb = chroma_client.from_documents(langchain_documents, OpenAIEmbeddings(), collection_name='deepshore-sitemap', client_settings=chromadb_settings, persist_directory=\"./chroma\")\n",
    "\n",
    "vectordb.persist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize storage\n",
    "\n",
    "visualize high-dimensional data with t-SNE a statistical method.\n",
    "\n",
    "https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding#:~:text=t%2Ddistributed%20stochastic%20neighbor%20embedding%20(t%2DSNE)%20is,two%20or%20three%2Ddimensional%20map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -e /Users/selamanse/Documents/GITHUB/chromaviz\n",
    "%pip install git+https://github.com/selamanse/chromaviz/\n",
    "\n",
    "from chromaviz import visualize_collection\n",
    "\n",
    "visualize_collection(col=vectordb._collection)\n",
    "\n",
    "# import requests\n",
    "# import json\n",
    "# data = vectordb._collection.get(include=[\"documents\", \"metadatas\",\"embeddings\"])\n",
    "# x = requests.post('http://lima-0:16875/import-data', data=json.dumps(data))\n",
    "# print(x)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize with atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Visualizing your pinecone vector database index in Atlas\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from nomic import atlas\n",
    "import nomic\n",
    "\n",
    "nomic.login(getpass.getpass(\"Nomic API Key:\"))\n",
    "\n",
    "num_embeddings = 999\n",
    "\n",
    "#now pull the embeddings out of pinecone by id\n",
    "vectors = vectordb._collection.get()\n",
    "\n",
    "ids = []\n",
    "info_jsons = []\n",
    "embeddings = []\n",
    "titles = []\n",
    "for id in vectors['ids']:\n",
    "    ids.append(id)\n",
    "    meta_source = vectordb._collection.get(ids=id, include=['metadatas'])['metadatas'][0]['Source']\n",
    "    text = vectordb._collection.get(ids=id, include=['documents'])['documents'][0]\n",
    "    idx = text.find('\\n### ')\n",
    "    info_jsons.append({'id': id, 'Source': meta_source, 'Document': text[idx + 6:idx + 50]})    \n",
    "    embeddings.append(vectordb._collection.get(ids=id, include=['embeddings'])['embeddings'][0])\n",
    "\n",
    "embeddings = np.array(embeddings)\n",
    "\n",
    "atlas.map_embeddings(embeddings=embeddings, data=info_jsons, id_field='id')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## retrieve relevant documents from vector store\n",
    "\n",
    "- show basic usage of what we can further do with the data inside a vector db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='[ ![Deepshore Logo\\nwhite](/user/themes/deepshore/images/Deepshore_LogoMINI_bis1000px_transparentRGB.svg)\\n![Deepshore\\nLogo](/user/themes/deepshore/images/Deepshore_LogoMINI_bis1000px_RGB.svg) ](/)\\n\\n[ Home ](/) [ Wissen ](/knowledge) [ Unternehmen ](/company) [ Chatbot\\n](/chat) [ Kontakt | Impressum | Datenschutz ](/company/contact-imprint-\\nprivacy) [ __   en ](/en/knowledge/2021-04-08)\\n\\n![](/images/d/e/e/p/s/deepshore-sap-cloud-archivierung-copyright-shutterstock-\\nden-rise-b6a6dcff.jpg?g-fe3cd0e1)\\n\\n##\\n\\n###  SAP-S/4-HANA-Archivierung in der Cloud – ArchiveLink versus BC-ILM versus\\nCMIS\\n\\n8\\\\. April 2021 \\\\-  Falk Borgmann\\n\\n[Beitrag](/knowledge/category:Beitrag) [Zentrale\\nSysteme](/knowledge/tag:Zentrale Systeme) [Cloud](/knowledge/tag:Cloud) [ECM\\nEIM](/knowledge/tag:ECM EIM)\\n\\nWas in der Welt der SAP-R3-Systeme notwendig, aber unbeliebt war, wird unter\\nS/4 HANA nicht unbedingt beliebter. Ich spreche hier nicht von teuren SAP-\\nBeratern, sondern vielmehr von der Datenauslagerung in einen Archiv-Storage.\\nAllein die richtige Formulierung im vorangegangenen Satz zu finden, zeigt die\\nProblematik. Es gibt nämlich verschiedene Gründe, seine Daten aus dem\\nführenden SAP-System auszulagern. Und es gibt unterschiedliche Schnittstellen,\\ndie genutzt werden können. Jede hat ihre eigene Geschichte und ihre eigenen\\nStärken und Schwächen. Um es gleich vorwegzunehmen: Wie so oft gibt es nicht\\nden einen besten Weg, der in allen Fällen zu präferieren ist. Es kommt selbst\\nbei SAP immer darauf an, worum es inhaltlich geht und in welcher IT-\\nInfrastruktur man sich bewegt oder bewegen will. Und leider ist seitens des\\nHerstellers keine klare Strategie zu erkennen, die einem Nutzer diesbezüglich\\neindeutige Leitlinien an die Hand geben würde.\\n\\n**S/4 HANA – wurde die Archivierung vergessen?**  \\nWas ich mich schon seit Langem frage, mir bisher aber noch niemand plausibel\\nerklären konnte, ist Folgendes: Hat SAP bei seiner HANA-Strategie die\\nDatenarchivierung vergessen? Oder war es eine bewusste Entscheidung in der\\nAnnahme, jeder Kunde würde bei HANA alle seine Daten für immer im\\nOnlinespeicher halten? Vielleicht gab es auch noch eine andere Überlegung, die\\nsich mir bisher nicht erschloss. Bis heute konnte mir noch niemand eine\\nnachvollziehbare Antwort auf diese Frage geben und so wird es wohl vorerst ein\\nGeheimnis bleiben. Dass die uneingeschränkte Datenhaltung im HANA nicht\\nunbedingt die preiswerteste Storage-Lösung ist, wurde jedoch schnell klar. Vor\\nallem dann nicht, wenn es um die GoBD*-relevante Aufbewahrung von Daten\\ninnerhalb eines Zeitraumes von sechs bis zehn Jahren geht. Dieser Umstand ist\\nauch dem Softwareunternehmen aus Walldorf kurz nach der Einführung von S/4\\nHANA bewusst geworden. Im Ergebnis erlebte die bereits totgesagte ArchiveLink-\\nSchnittstelle (folgend AL) so etwas wie eine Renaissance. Auf Druck der im\\nDSAG** organisierten Kunden ist AL lebendiger denn je – auch in der S/4-HANA-\\nWelt. Im Zuge dieser Diskussion sah sich SAP darüberhinaus genötigt, den\\neinstigen Ladenhüter „ILM“ mit seiner BC-ILM-Schnittstelle den Kunden quasi\\nkostenfrei zur Verfügung zu stellen.  \\nIm zeitlichen Verlauf wurde das Thema SAP-Datenverwaltung, Auslagerung und\\nArchivierung durch ein weiteres Ereignis verstärkt: das Inkrafttreten der\\nDSGVO. Durch die DSGVO entstand die Notwendigkeit, sich auch um Lösch- und\\nAufbewahrungskonzepte von SAP-Daten zu kümmern – unabhängig davon, wo die SAP-\\nDaten verwaltet werden. Aufgrund der geschilderten Kausalitäten ist die\\nVerfügbarkeit der AL- und BC-ILM-Schnittstelle nicht konsistent innerhalb des\\ngesamten HANA-Kosmos und somit auch nicht für jedes SAP-Modul gleichermaßen\\nverfügbar.\\n\\n**ArchiveLink versus BC-ILM**  \\nWichtig ist vor allem, sich die unterschiedlichen Use Cases der beiden\\nSchnittstellen bewusst zu machen. Bei AL geht es um die klassische Daten- und\\nObjektarchivierung – also die Ablage von Ausgangs- und Eingangsbelegen sowie\\nDrucklisten und Reorg-Daten. Hauptgründe für die Nutzung dieser Schnittstelle\\nist die Erfüllung der GoBD-Anforderungen (Langzeitarchivierung) und eine\\nVerschlankung der produktiven SAP-Datenbanken (Reorg). Der fachliche Kontext\\nund die Benutzeroberfläche verbleiben vollständig im SAP. Das Archiv ist somit\\nnicht mehr als ein nicht fachlicher Compliance-Storage hinter dem ERP. Das\\nfunktionale Portfolio klassischer ECM-/DMS-Systeme, wie OpenText, d.velop oder\\nSER kann man sich in diesem Szenario sparen – das geht billiger und besser.\\nFirmen wie KGS oder nextevolution bieten schlankere Lösungen an, wobei sich\\nhier die Spreu auch vom Weizen trennt, wenn es um echte Cloudtechnologie\\n(Container Services unter OpenShift oder Kubernetes) geht.  \\nMit der Notwendigkeit, Daten oder Informationen auch DSGVO-konform zu\\nverwalten, kommt SAP-ILM mit seiner BC-ILM Schnittstelle in Betracht. Über die\\nreine Archivierung und Aufbewahrung hinaus kann mithilfe dieses Ansatzes auch\\nsicher gestellt werden, dass z. B. auch berechtigte Löschanforderungen für\\nbestimmte Daten gewährleistet werden können (Data Retention Manager).\\nWeiterhin werden Funktionen wie Systemstilllegungen unterstützt, ohne dabei\\nauf die Möglichkeit zu verzichten, die archivierten Daten weiterhin für\\nBerichts- oder Auditzwecke im Zugriff zu behalten. Das gilt für Informationen\\ninnerhalb und außerhalb des SAP-Systems. Man könnte also BC-ILM als die\\npotenziell klügere und mächtigere Variante von AL bezeichnen, obwohl der\\nAufwand einer Implementierung innerhalb von SAP aufwendiger ist oder sein\\nkann. Es kommt ganz darauf an, was genau getan werden soll.  \\nHalten wir fest: Sowohl die AL- als auch die BC-LIM-Schnittstelle kann dazu\\ngenutzt werden, Daten im Sinne der GoBD für die gesetzliche Aufbewahrungsfrist\\nzu nutzen. Darüber hinaus kann mit beiden Schnittstellen auch ein produktives\\nSAP-System von unnötigen (Alt-)Daten entlastet werden, um Kosten in der\\nInfrastruktur zu reduzieren.\\n\\n**SAP-CMIS – der Link in die ECM-Welt**  \\nSchon 2010 beteiligte sich SAP im Rahmen einer OASIS-Initiative zusammen mit\\nanderen Unternehmen an der Gestaltung von CMIS (Content Management\\nInteroperability Services). Dabei handelt es sich um eine offene API, um im\\nKern ein beliebiges ECM-System anzusprechen, ohne dabei die proprietäre API\\ndes jeweiligen ECM-Produkts zu kennen oder zu nutzen. Es geht also um mehr als\\ndie einfache Datenablage wie beim klassischen AL-Szenario, gleichwohl man AL-\\nUse Cases auf einer fachlichen Ebene auch mit CMIS adressieren könnte.\\nZusätzlich ergibt sich die Möglichkeit, z. B. auch fachliche Indexdaten aus\\nSAP heraus in eine ECM-Plattform zu übertragen. Somit wird der „dumme“ Storage\\ndes ECM-Systems potenziell mit beliebig vielen Informationen oder Daten\\nerweitert, die dann auch innerhalb das ECM-Systems autark genutzt werden\\nkönnten (z. B. für Workflows, Aktenmodelle etc.). Sofern das SAP-System aber\\ndie fachlichen Prozesse beherbergen soll und die Schnittstelle lediglich zur\\ntechnischen Datenauslagerung oder Erfüllung rechtlicher Anforderungen dient,\\nergibt sich technisch kein zusätzlicher Nutzen durch CMIS. Im Gegenteil, es\\nist in diesem Fall eher die berühmte Kanone, mit der auf einen Spatzen\\ngeschossen wird. Die Entscheidung, welche Use Cases adressiert werden sollen\\nbzw. welche technische Strategie ein Unternehmen eingeschlagen hat, hilft also\\nbei der Entscheidung für oder gegen CMIS, AL oder BC-ILM.\\n\\n**Und in der Cloud …?**  \\nIm SAP-Kontext ist es nicht ganz einfach, über „die Cloud“ zu sprechen. Das\\nwas SAP selbst als seine Cloud-Welt für HANA anbietet, hat meiner Meinung nach\\nnun wirklich nichts mit Cloud-Technologie zu tun. Früher hat man so etwas\\nManaged Services in einem externen Rechenzentrum genannt. Aber Cloud klingt\\ndeutlich moderner. Und machen wir uns nichts vor: SAP ist alles, aber keine\\nSoftware, die man in einer echten Cloudumgebung mit den Mehrwerten einer\\nCloud-Native-Technologie sinnvoll betreiben kann. Mal schnell ein S/4 HANA\\ndeployen, dann horizontal „raus skalieren“, wenn die Last steigt und\\nanschließend die PODs einfach im Kubernetes Cluster terminieren? Wenn ein\\nLeser das schon mal geschafft hat und mir dies live demonstrieren kann,\\nspendiere ich auch einen Kasten Bier oder wahlweise Club-Mate.  \\nAber SAP hat auch seine Qualitäten. Ein Ozeanriese mag zwar nicht sonderlich\\nagil und flexibel sein, dafür ist er aber in der Lage, auf fest definierten\\nWasserstraßen ordentliche Mengen und große Lasten zu bewegen. Es gibt ja auch\\nGründe, warum Banken ihre relativ teuren Hostsysteme nicht loswerden.  \\nWie auch immer: Die Frage ist, welche der Schnittstellen aus technischer\\nPerspektive Cloud-fähig ist und dort am besten betrieben werden kann. Die\\nkurze und einfache Antwort: Diese Frage stellt sich gar nicht, da SAP selbst\\nkeine Cloud-Native-Technologie ist. Aus diesem Grund ist die Illustration zu\\ndiesem Beitrag unter ironischen Gesichtspunkten ausgewählt worden. Ob SAP –\\naus welchen Gründen auch immer – es mal schaffen wird, sich von ArchiveLink zu\\ntrennen, bleibt das Geheimnis der Walldorfer Softwareschmiede. Von daher\\nsollten Unternehmen zuerst auf ihren Use Case und die IT-Strategie schauen und\\nsich nicht anderweitig nervös machen lassen.  \\n*GoBD = Grundsätze zur ordnungsmäßigen Führung und Aufbewahrung von Büchern, Aufzeichnungen und Unterlagen in elektronischer Form sowie zum Datenzugriff = [Verwaltungsanweisung des Bundesministerium der Finanzen der Bundesrepublik Deutschland](https://www.bundesfinanzministerium.de/Content/DE/Downloads/BMF_Schreiben/Weitere_Steuerthemen/Abgabenordnung/2019-11-28-GoBD.html)\\n\\n**DSAG = [Deutschsprachige SAP Anwendergruppe e. V.](https://www.dsag.de/)\\n\\nTeilen\\n\\n__\\n\\nLink in Zwischenablage kopiert.\\n\\nMehr\\n\\n[ ](/knowledge/2023-05-08)\\n\\n[ Mit standard Framework\\n\\n##  Loadtesting als Day-2-Operations von Container Lösungen\\n\\n](/knowledge/2023-05-08)\\n\\n[Beitrag](/knowledge/category:Beitrag) [Kubernetes](/knowledge/tag:Kubernetes)\\n[Deployment](/knowledge/tag:Deployment) [Open-Source](/knowledge/tag:Open-\\nSource)\\n\\n[ ](/knowledge/ki-und-ihr-potenzial-neue-realitaeten-zu-erschaffen)\\n\\n[\\n\\n##  KI und ihr Potenzial, neue Realitäten zu erschaffen\\n\\n](/knowledge/ki-und-ihr-potenzial-neue-realitaeten-zu-erschaffen)\\n\\n[Beitrag](/knowledge/category:Beitrag) [Künstliche Intelligenz\\n(KI)](/knowledge/tag:Künstliche Intelligenz \\\\(KI\\\\))\\n\\n[ ](/knowledge/ki-facebook-leak-open-source-community-fordert-tech-konzerne-\\nheraus)\\n\\n[ KI-Facebook-Leak\\n\\n##  Open-Source Community fordert Tech-Konzerne heraus\\n\\n](/knowledge/ki-facebook-leak-open-source-community-fordert-tech-konzerne-\\nheraus)\\n\\n[Beitrag](/knowledge/category:Beitrag) [Künstliche Intelligenz\\n(KI)](/knowledge/tag:Künstliche Intelligenz \\\\(KI\\\\))\\n\\n[ Noch mehr... ](/knowledge)\\n\\n**Deepshore GmbH**  \\nVan-der-Smissen-Straße 9, 22767 Hamburg  \\nTel +49 40 46664 296\\n\\n[Impressum](/de/company/contact-imprint-privacy) |\\n[Kontakt](/de/company/contact-imprint-privacy) |\\n[Datenschutzerklärung](/de/company/contact-imprint-privacy) |\\n[AGB](/de/company/conditions)\\n\\n', metadata={'Source': 'https://deepshore.de/knowledge/2021-04-08'}),\n",
       " Document(page_content='[ ![Deepshore Logo\\nwhite](/user/themes/deepshore/images/Deepshore_LogoMINI_bis1000px_transparentRGB.svg)\\n![Deepshore\\nLogo](/user/themes/deepshore/images/Deepshore_LogoMINI_bis1000px_RGB.svg) ](/)\\n\\n[ Home ](/) [ Wissen ](/knowledge) [ Unternehmen ](/company) [ Chatbot\\n](/chat) [ Kontakt | Impressum | Datenschutz ](/company/contact-imprint-\\nprivacy) [ __   en ](/en/knowledge/2021-04-08)\\n\\n![](/images/d/e/e/p/s/deepshore-sap-cloud-archivierung-copyright-shutterstock-\\nden-rise-b6a6dcff.jpg?g-fe3cd0e1)\\n\\n##\\n\\n###  SAP-S/4-HANA-Archivierung in der Cloud – ArchiveLink versus BC-ILM versus\\nCMIS\\n\\n8\\\\. April 2021 \\\\-  Falk Borgmann\\n\\n[Beitrag](/knowledge/category:Beitrag) [Zentrale\\nSysteme](/knowledge/tag:Zentrale Systeme) [Cloud](/knowledge/tag:Cloud) [ECM\\nEIM](/knowledge/tag:ECM EIM)\\n\\nWas in der Welt der SAP-R3-Systeme notwendig, aber unbeliebt war, wird unter\\nS/4 HANA nicht unbedingt beliebter. Ich spreche hier nicht von teuren SAP-\\nBeratern, sondern vielmehr von der Datenauslagerung in einen Archiv-Storage.\\nAllein die richtige Formulierung im vorangegangenen Satz zu finden, zeigt die\\nProblematik. Es gibt nämlich verschiedene Gründe, seine Daten aus dem\\nführenden SAP-System auszulagern. Und es gibt unterschiedliche Schnittstellen,\\ndie genutzt werden können. Jede hat ihre eigene Geschichte und ihre eigenen\\nStärken und Schwächen. Um es gleich vorwegzunehmen: Wie so oft gibt es nicht\\nden einen besten Weg, der in allen Fällen zu präferieren ist. Es kommt selbst\\nbei SAP immer darauf an, worum es inhaltlich geht und in welcher IT-\\nInfrastruktur man sich bewegt oder bewegen will. Und leider ist seitens des\\nHerstellers keine klare Strategie zu erkennen, die einem Nutzer diesbezüglich\\neindeutige Leitlinien an die Hand geben würde.\\n\\n**S/4 HANA – wurde die Archivierung vergessen?**  \\nWas ich mich schon seit Langem frage, mir bisher aber noch niemand plausibel\\nerklären konnte, ist Folgendes: Hat SAP bei seiner HANA-Strategie die\\nDatenarchivierung vergessen? Oder war es eine bewusste Entscheidung in der\\nAnnahme, jeder Kunde würde bei HANA alle seine Daten für immer im\\nOnlinespeicher halten? Vielleicht gab es auch noch eine andere Überlegung, die\\nsich mir bisher nicht erschloss. Bis heute konnte mir noch niemand eine\\nnachvollziehbare Antwort auf diese Frage geben und so wird es wohl vorerst ein\\nGeheimnis bleiben. Dass die uneingeschränkte Datenhaltung im HANA nicht\\nunbedingt die preiswerteste Storage-Lösung ist, wurde jedoch schnell klar. Vor\\nallem dann nicht, wenn es um die GoBD*-relevante Aufbewahrung von Daten\\ninnerhalb eines Zeitraumes von sechs bis zehn Jahren geht. Dieser Umstand ist\\nauch dem Softwareunternehmen aus Walldorf kurz nach der Einführung von S/4\\nHANA bewusst geworden. Im Ergebnis erlebte die bereits totgesagte ArchiveLink-\\nSchnittstelle (folgend AL) so etwas wie eine Renaissance. Auf Druck der im\\nDSAG** organisierten Kunden ist AL lebendiger denn je – auch in der S/4-HANA-\\nWelt. Im Zuge dieser Diskussion sah sich SAP darüberhinaus genötigt, den\\neinstigen Ladenhüter „ILM“ mit seiner BC-ILM-Schnittstelle den Kunden quasi\\nkostenfrei zur Verfügung zu stellen.  \\nIm zeitlichen Verlauf wurde das Thema SAP-Datenverwaltung, Auslagerung und\\nArchivierung durch ein weiteres Ereignis verstärkt: das Inkrafttreten der\\nDSGVO. Durch die DSGVO entstand die Notwendigkeit, sich auch um Lösch- und\\nAufbewahrungskonzepte von SAP-Daten zu kümmern – unabhängig davon, wo die SAP-\\nDaten verwaltet werden. Aufgrund der geschilderten Kausalitäten ist die\\nVerfügbarkeit der AL- und BC-ILM-Schnittstelle nicht konsistent innerhalb des\\ngesamten HANA-Kosmos und somit auch nicht für jedes SAP-Modul gleichermaßen\\nverfügbar.\\n\\n**ArchiveLink versus BC-ILM**  \\nWichtig ist vor allem, sich die unterschiedlichen Use Cases der beiden\\nSchnittstellen bewusst zu machen. Bei AL geht es um die klassische Daten- und\\nObjektarchivierung – also die Ablage von Ausgangs- und Eingangsbelegen sowie\\nDrucklisten und Reorg-Daten. Hauptgründe für die Nutzung dieser Schnittstelle\\nist die Erfüllung der GoBD-Anforderungen (Langzeitarchivierung) und eine\\nVerschlankung der produktiven SAP-Datenbanken (Reorg). Der fachliche Kontext\\nund die Benutzeroberfläche verbleiben vollständig im SAP. Das Archiv ist somit\\nnicht mehr als ein nicht fachlicher Compliance-Storage hinter dem ERP. Das\\nfunktionale Portfolio klassischer ECM-/DMS-Systeme, wie OpenText, d.velop oder\\nSER kann man sich in diesem Szenario sparen – das geht billiger und besser.\\nFirmen wie KGS oder nextevolution bieten schlankere Lösungen an, wobei sich\\nhier die Spreu auch vom Weizen trennt, wenn es um echte Cloudtechnologie\\n(Container Services unter OpenShift oder Kubernetes) geht.  \\nMit der Notwendigkeit, Daten oder Informationen auch DSGVO-konform zu\\nverwalten, kommt SAP-ILM mit seiner BC-ILM Schnittstelle in Betracht. Über die\\nreine Archivierung und Aufbewahrung hinaus kann mithilfe dieses Ansatzes auch\\nsicher gestellt werden, dass z. B. auch berechtigte Löschanforderungen für\\nbestimmte Daten gewährleistet werden können (Data Retention Manager).\\nWeiterhin werden Funktionen wie Systemstilllegungen unterstützt, ohne dabei\\nauf die Möglichkeit zu verzichten, die archivierten Daten weiterhin für\\nBerichts- oder Auditzwecke im Zugriff zu behalten. Das gilt für Informationen\\ninnerhalb und außerhalb des SAP-Systems. Man könnte also BC-ILM als die\\npotenziell klügere und mächtigere Variante von AL bezeichnen, obwohl der\\nAufwand einer Implementierung innerhalb von SAP aufwendiger ist oder sein\\nkann. Es kommt ganz darauf an, was genau getan werden soll.  \\nHalten wir fest: Sowohl die AL- als auch die BC-LIM-Schnittstelle kann dazu\\ngenutzt werden, Daten im Sinne der GoBD für die gesetzliche Aufbewahrungsfrist\\nzu nutzen. Darüber hinaus kann mit beiden Schnittstellen auch ein produktives\\nSAP-System von unnötigen (Alt-)Daten entlastet werden, um Kosten in der\\nInfrastruktur zu reduzieren.\\n\\n**SAP-CMIS – der Link in die ECM-Welt**  \\nSchon 2010 beteiligte sich SAP im Rahmen einer OASIS-Initiative zusammen mit\\nanderen Unternehmen an der Gestaltung von CMIS (Content Management\\nInteroperability Services). Dabei handelt es sich um eine offene API, um im\\nKern ein beliebiges ECM-System anzusprechen, ohne dabei die proprietäre API\\ndes jeweiligen ECM-Produkts zu kennen oder zu nutzen. Es geht also um mehr als\\ndie einfache Datenablage wie beim klassischen AL-Szenario, gleichwohl man AL-\\nUse Cases auf einer fachlichen Ebene auch mit CMIS adressieren könnte.\\nZusätzlich ergibt sich die Möglichkeit, z. B. auch fachliche Indexdaten aus\\nSAP heraus in eine ECM-Plattform zu übertragen. Somit wird der „dumme“ Storage\\ndes ECM-Systems potenziell mit beliebig vielen Informationen oder Daten\\nerweitert, die dann auch innerhalb das ECM-Systems autark genutzt werden\\nkönnten (z. B. für Workflows, Aktenmodelle etc.). Sofern das SAP-System aber\\ndie fachlichen Prozesse beherbergen soll und die Schnittstelle lediglich zur\\ntechnischen Datenauslagerung oder Erfüllung rechtlicher Anforderungen dient,\\nergibt sich technisch kein zusätzlicher Nutzen durch CMIS. Im Gegenteil, es\\nist in diesem Fall eher die berühmte Kanone, mit der auf einen Spatzen\\ngeschossen wird. Die Entscheidung, welche Use Cases adressiert werden sollen\\nbzw. welche technische Strategie ein Unternehmen eingeschlagen hat, hilft also\\nbei der Entscheidung für oder gegen CMIS, AL oder BC-ILM.\\n\\n**Und in der Cloud …?**  \\nIm SAP-Kontext ist es nicht ganz einfach, über „die Cloud“ zu sprechen. Das\\nwas SAP selbst als seine Cloud-Welt für HANA anbietet, hat meiner Meinung nach\\nnun wirklich nichts mit Cloud-Technologie zu tun. Früher hat man so etwas\\nManaged Services in einem externen Rechenzentrum genannt. Aber Cloud klingt\\ndeutlich moderner. Und machen wir uns nichts vor: SAP ist alles, aber keine\\nSoftware, die man in einer echten Cloudumgebung mit den Mehrwerten einer\\nCloud-Native-Technologie sinnvoll betreiben kann. Mal schnell ein S/4 HANA\\ndeployen, dann horizontal „raus skalieren“, wenn die Last steigt und\\nanschließend die PODs einfach im Kubernetes Cluster terminieren? Wenn ein\\nLeser das schon mal geschafft hat und mir dies live demonstrieren kann,\\nspendiere ich auch einen Kasten Bier oder wahlweise Club-Mate.  \\nAber SAP hat auch seine Qualitäten. Ein Ozeanriese mag zwar nicht sonderlich\\nagil und flexibel sein, dafür ist er aber in der Lage, auf fest definierten\\nWasserstraßen ordentliche Mengen und große Lasten zu bewegen. Es gibt ja auch\\nGründe, warum Banken ihre relativ teuren Hostsysteme nicht loswerden.  \\nWie auch immer: Die Frage ist, welche der Schnittstellen aus technischer\\nPerspektive Cloud-fähig ist und dort am besten betrieben werden kann. Die\\nkurze und einfache Antwort: Diese Frage stellt sich gar nicht, da SAP selbst\\nkeine Cloud-Native-Technologie ist. Aus diesem Grund ist die Illustration zu\\ndiesem Beitrag unter ironischen Gesichtspunkten ausgewählt worden. Ob SAP –\\naus welchen Gründen auch immer – es mal schaffen wird, sich von ArchiveLink zu\\ntrennen, bleibt das Geheimnis der Walldorfer Softwareschmiede. Von daher\\nsollten Unternehmen zuerst auf ihren Use Case und die IT-Strategie schauen und\\nsich nicht anderweitig nervös machen lassen.  \\n*GoBD = Grundsätze zur ordnungsmäßigen Führung und Aufbewahrung von Büchern, Aufzeichnungen und Unterlagen in elektronischer Form sowie zum Datenzugriff = [Verwaltungsanweisung des Bundesministerium der Finanzen der Bundesrepublik Deutschland](https://www.bundesfinanzministerium.de/Content/DE/Downloads/BMF_Schreiben/Weitere_Steuerthemen/Abgabenordnung/2019-11-28-GoBD.html)\\n\\n**DSAG = [Deutschsprachige SAP Anwendergruppe e. V.](https://www.dsag.de/)\\n\\nTeilen\\n\\n__\\n\\nLink in Zwischenablage kopiert.\\n\\nMehr\\n\\n[ ](/knowledge/2023-05-08)\\n\\n[ Mit standard Framework\\n\\n##  Loadtesting als Day-2-Operations von Container Lösungen\\n\\n](/knowledge/2023-05-08)\\n\\n[Beitrag](/knowledge/category:Beitrag) [Kubernetes](/knowledge/tag:Kubernetes)\\n[Deployment](/knowledge/tag:Deployment) [Open-Source](/knowledge/tag:Open-\\nSource)\\n\\n[ ](/knowledge/ki-und-ihr-potenzial-neue-realitaeten-zu-erschaffen)\\n\\n[\\n\\n##  KI und ihr Potenzial, neue Realitäten zu erschaffen\\n\\n](/knowledge/ki-und-ihr-potenzial-neue-realitaeten-zu-erschaffen)\\n\\n[Beitrag](/knowledge/category:Beitrag) [Künstliche Intelligenz\\n(KI)](/knowledge/tag:Künstliche Intelligenz \\\\(KI\\\\))\\n\\n[ ](/knowledge/ki-facebook-leak-open-source-community-fordert-tech-konzerne-\\nheraus)\\n\\n[ KI-Facebook-Leak\\n\\n##  Open-Source Community fordert Tech-Konzerne heraus\\n\\n](/knowledge/ki-facebook-leak-open-source-community-fordert-tech-konzerne-\\nheraus)\\n\\n[Beitrag](/knowledge/category:Beitrag) [Künstliche Intelligenz\\n(KI)](/knowledge/tag:Künstliche Intelligenz \\\\(KI\\\\))\\n\\n[ Noch mehr... ](/knowledge)\\n\\n**Deepshore GmbH**  \\nVan-der-Smissen-Straße 9, 22767 Hamburg  \\nTel +49 40 46664 296\\n\\n[Impressum](/de/company/contact-imprint-privacy) |\\n[Kontakt](/de/company/contact-imprint-privacy) |\\n[Datenschutzerklärung](/de/company/contact-imprint-privacy) |\\n[AGB](/de/company/conditions)\\n\\n', metadata={'Source': 'https://deepshore.de/knowledge/2021-04-08'}),\n",
       " Document(page_content='[ ![Deepshore Logo\\nwhite](/user/themes/deepshore/images/Deepshore_LogoMINI_bis1000px_transparentRGB.svg)\\n![Deepshore\\nLogo](/user/themes/deepshore/images/Deepshore_LogoMINI_bis1000px_RGB.svg) ](/)\\n\\n[ Home ](/) [ Wissen ](/knowledge) [ Unternehmen ](/company) [ Chatbot\\n](/chat) [ Kontakt | Impressum | Datenschutz ](/company/contact-imprint-\\nprivacy) [ __   en ](/en/knowledge/2021-04-08)\\n\\n![](/images/d/e/e/p/s/deepshore-sap-cloud-archivierung-copyright-shutterstock-\\nden-rise-b6a6dcff.jpg?g-fe3cd0e1)\\n\\n##\\n\\n###  SAP-S/4-HANA-Archivierung in der Cloud – ArchiveLink versus BC-ILM versus\\nCMIS\\n\\n8\\\\. April 2021 \\\\-  Falk Borgmann\\n\\n[Beitrag](/knowledge/category:Beitrag) [Zentrale\\nSysteme](/knowledge/tag:Zentrale Systeme) [Cloud](/knowledge/tag:Cloud) [ECM\\nEIM](/knowledge/tag:ECM EIM)\\n\\nWas in der Welt der SAP-R3-Systeme notwendig, aber unbeliebt war, wird unter\\nS/4 HANA nicht unbedingt beliebter. Ich spreche hier nicht von teuren SAP-\\nBeratern, sondern vielmehr von der Datenauslagerung in einen Archiv-Storage.\\nAllein die richtige Formulierung im vorangegangenen Satz zu finden, zeigt die\\nProblematik. Es gibt nämlich verschiedene Gründe, seine Daten aus dem\\nführenden SAP-System auszulagern. Und es gibt unterschiedliche Schnittstellen,\\ndie genutzt werden können. Jede hat ihre eigene Geschichte und ihre eigenen\\nStärken und Schwächen. Um es gleich vorwegzunehmen: Wie so oft gibt es nicht\\nden einen besten Weg, der in allen Fällen zu präferieren ist. Es kommt selbst\\nbei SAP immer darauf an, worum es inhaltlich geht und in welcher IT-\\nInfrastruktur man sich bewegt oder bewegen will. Und leider ist seitens des\\nHerstellers keine klare Strategie zu erkennen, die einem Nutzer diesbezüglich\\neindeutige Leitlinien an die Hand geben würde.\\n\\n**S/4 HANA – wurde die Archivierung vergessen?**  \\nWas ich mich schon seit Langem frage, mir bisher aber noch niemand plausibel\\nerklären konnte, ist Folgendes: Hat SAP bei seiner HANA-Strategie die\\nDatenarchivierung vergessen? Oder war es eine bewusste Entscheidung in der\\nAnnahme, jeder Kunde würde bei HANA alle seine Daten für immer im\\nOnlinespeicher halten? Vielleicht gab es auch noch eine andere Überlegung, die\\nsich mir bisher nicht erschloss. Bis heute konnte mir noch niemand eine\\nnachvollziehbare Antwort auf diese Frage geben und so wird es wohl vorerst ein\\nGeheimnis bleiben. Dass die uneingeschränkte Datenhaltung im HANA nicht\\nunbedingt die preiswerteste Storage-Lösung ist, wurde jedoch schnell klar. Vor\\nallem dann nicht, wenn es um die GoBD*-relevante Aufbewahrung von Daten\\ninnerhalb eines Zeitraumes von sechs bis zehn Jahren geht. Dieser Umstand ist\\nauch dem Softwareunternehmen aus Walldorf kurz nach der Einführung von S/4\\nHANA bewusst geworden. Im Ergebnis erlebte die bereits totgesagte ArchiveLink-\\nSchnittstelle (folgend AL) so etwas wie eine Renaissance. Auf Druck der im\\nDSAG** organisierten Kunden ist AL lebendiger denn je – auch in der S/4-HANA-\\nWelt. Im Zuge dieser Diskussion sah sich SAP darüberhinaus genötigt, den\\neinstigen Ladenhüter „ILM“ mit seiner BC-ILM-Schnittstelle den Kunden quasi\\nkostenfrei zur Verfügung zu stellen.  \\nIm zeitlichen Verlauf wurde das Thema SAP-Datenverwaltung, Auslagerung und\\nArchivierung durch ein weiteres Ereignis verstärkt: das Inkrafttreten der\\nDSGVO. Durch die DSGVO entstand die Notwendigkeit, sich auch um Lösch- und\\nAufbewahrungskonzepte von SAP-Daten zu kümmern – unabhängig davon, wo die SAP-\\nDaten verwaltet werden. Aufgrund der geschilderten Kausalitäten ist die\\nVerfügbarkeit der AL- und BC-ILM-Schnittstelle nicht konsistent innerhalb des\\ngesamten HANA-Kosmos und somit auch nicht für jedes SAP-Modul gleichermaßen\\nverfügbar.\\n\\n**ArchiveLink versus BC-ILM**  \\nWichtig ist vor allem, sich die unterschiedlichen Use Cases der beiden\\nSchnittstellen bewusst zu machen. Bei AL geht es um die klassische Daten- und\\nObjektarchivierung – also die Ablage von Ausgangs- und Eingangsbelegen sowie\\nDrucklisten und Reorg-Daten. Hauptgründe für die Nutzung dieser Schnittstelle\\nist die Erfüllung der GoBD-Anforderungen (Langzeitarchivierung) und eine\\nVerschlankung der produktiven SAP-Datenbanken (Reorg). Der fachliche Kontext\\nund die Benutzeroberfläche verbleiben vollständig im SAP. Das Archiv ist somit\\nnicht mehr als ein nicht fachlicher Compliance-Storage hinter dem ERP. Das\\nfunktionale Portfolio klassischer ECM-/DMS-Systeme, wie OpenText, d.velop oder\\nSER kann man sich in diesem Szenario sparen – das geht billiger und besser.\\nFirmen wie KGS oder nextevolution bieten schlankere Lösungen an, wobei sich\\nhier die Spreu auch vom Weizen trennt, wenn es um echte Cloudtechnologie\\n(Container Services unter OpenShift oder Kubernetes) geht.  \\nMit der Notwendigkeit, Daten oder Informationen auch DSGVO-konform zu\\nverwalten, kommt SAP-ILM mit seiner BC-ILM Schnittstelle in Betracht. Über die\\nreine Archivierung und Aufbewahrung hinaus kann mithilfe dieses Ansatzes auch\\nsicher gestellt werden, dass z. B. auch berechtigte Löschanforderungen für\\nbestimmte Daten gewährleistet werden können (Data Retention Manager).\\nWeiterhin werden Funktionen wie Systemstilllegungen unterstützt, ohne dabei\\nauf die Möglichkeit zu verzichten, die archivierten Daten weiterhin für\\nBerichts- oder Auditzwecke im Zugriff zu behalten. Das gilt für Informationen\\ninnerhalb und außerhalb des SAP-Systems. Man könnte also BC-ILM als die\\npotenziell klügere und mächtigere Variante von AL bezeichnen, obwohl der\\nAufwand einer Implementierung innerhalb von SAP aufwendiger ist oder sein\\nkann. Es kommt ganz darauf an, was genau getan werden soll.  \\nHalten wir fest: Sowohl die AL- als auch die BC-LIM-Schnittstelle kann dazu\\ngenutzt werden, Daten im Sinne der GoBD für die gesetzliche Aufbewahrungsfrist\\nzu nutzen. Darüber hinaus kann mit beiden Schnittstellen auch ein produktives\\nSAP-System von unnötigen (Alt-)Daten entlastet werden, um Kosten in der\\nInfrastruktur zu reduzieren.\\n\\n**SAP-CMIS – der Link in die ECM-Welt**  \\nSchon 2010 beteiligte sich SAP im Rahmen einer OASIS-Initiative zusammen mit\\nanderen Unternehmen an der Gestaltung von CMIS (Content Management\\nInteroperability Services). Dabei handelt es sich um eine offene API, um im\\nKern ein beliebiges ECM-System anzusprechen, ohne dabei die proprietäre API\\ndes jeweiligen ECM-Produkts zu kennen oder zu nutzen. Es geht also um mehr als\\ndie einfache Datenablage wie beim klassischen AL-Szenario, gleichwohl man AL-\\nUse Cases auf einer fachlichen Ebene auch mit CMIS adressieren könnte.\\nZusätzlich ergibt sich die Möglichkeit, z. B. auch fachliche Indexdaten aus\\nSAP heraus in eine ECM-Plattform zu übertragen. Somit wird der „dumme“ Storage\\ndes ECM-Systems potenziell mit beliebig vielen Informationen oder Daten\\nerweitert, die dann auch innerhalb das ECM-Systems autark genutzt werden\\nkönnten (z. B. für Workflows, Aktenmodelle etc.). Sofern das SAP-System aber\\ndie fachlichen Prozesse beherbergen soll und die Schnittstelle lediglich zur\\ntechnischen Datenauslagerung oder Erfüllung rechtlicher Anforderungen dient,\\nergibt sich technisch kein zusätzlicher Nutzen durch CMIS. Im Gegenteil, es\\nist in diesem Fall eher die berühmte Kanone, mit der auf einen Spatzen\\ngeschossen wird. Die Entscheidung, welche Use Cases adressiert werden sollen\\nbzw. welche technische Strategie ein Unternehmen eingeschlagen hat, hilft also\\nbei der Entscheidung für oder gegen CMIS, AL oder BC-ILM.\\n\\n**Und in der Cloud …?**  \\nIm SAP-Kontext ist es nicht ganz einfach, über „die Cloud“ zu sprechen. Das\\nwas SAP selbst als seine Cloud-Welt für HANA anbietet, hat meiner Meinung nach\\nnun wirklich nichts mit Cloud-Technologie zu tun. Früher hat man so etwas\\nManaged Services in einem externen Rechenzentrum genannt. Aber Cloud klingt\\ndeutlich moderner. Und machen wir uns nichts vor: SAP ist alles, aber keine\\nSoftware, die man in einer echten Cloudumgebung mit den Mehrwerten einer\\nCloud-Native-Technologie sinnvoll betreiben kann. Mal schnell ein S/4 HANA\\ndeployen, dann horizontal „raus skalieren“, wenn die Last steigt und\\nanschließend die PODs einfach im Kubernetes Cluster terminieren? Wenn ein\\nLeser das schon mal geschafft hat und mir dies live demonstrieren kann,\\nspendiere ich auch einen Kasten Bier oder wahlweise Club-Mate.  \\nAber SAP hat auch seine Qualitäten. Ein Ozeanriese mag zwar nicht sonderlich\\nagil und flexibel sein, dafür ist er aber in der Lage, auf fest definierten\\nWasserstraßen ordentliche Mengen und große Lasten zu bewegen. Es gibt ja auch\\nGründe, warum Banken ihre relativ teuren Hostsysteme nicht loswerden.  \\nWie auch immer: Die Frage ist, welche der Schnittstellen aus technischer\\nPerspektive Cloud-fähig ist und dort am besten betrieben werden kann. Die\\nkurze und einfache Antwort: Diese Frage stellt sich gar nicht, da SAP selbst\\nkeine Cloud-Native-Technologie ist. Aus diesem Grund ist die Illustration zu\\ndiesem Beitrag unter ironischen Gesichtspunkten ausgewählt worden. Ob SAP –\\naus welchen Gründen auch immer – es mal schaffen wird, sich von ArchiveLink zu\\ntrennen, bleibt das Geheimnis der Walldorfer Softwareschmiede. Von daher\\nsollten Unternehmen zuerst auf ihren Use Case und die IT-Strategie schauen und\\nsich nicht anderweitig nervös machen lassen.  \\n*GoBD = Grundsätze zur ordnungsmäßigen Führung und Aufbewahrung von Büchern, Aufzeichnungen und Unterlagen in elektronischer Form sowie zum Datenzugriff = [Verwaltungsanweisung des Bundesministerium der Finanzen der Bundesrepublik Deutschland](https://www.bundesfinanzministerium.de/Content/DE/Downloads/BMF_Schreiben/Weitere_Steuerthemen/Abgabenordnung/2019-11-28-GoBD.html)\\n\\n**DSAG = [Deutschsprachige SAP Anwendergruppe e. V.](https://www.dsag.de/)\\n\\nTeilen\\n\\n__\\n\\nLink in Zwischenablage kopiert.\\n\\nMehr\\n\\n[ ](/knowledge/2023-05-08)\\n\\n[ Mit standard Framework\\n\\n##  Loadtesting als Day-2-Operations von Container Lösungen\\n\\n](/knowledge/2023-05-08)\\n\\n[Beitrag](/knowledge/category:Beitrag) [Kubernetes](/knowledge/tag:Kubernetes)\\n[Deployment](/knowledge/tag:Deployment) [Open-Source](/knowledge/tag:Open-\\nSource)\\n\\n[ ](/knowledge/ki-und-ihr-potenzial-neue-realitaeten-zu-erschaffen)\\n\\n[\\n\\n##  KI und ihr Potenzial, neue Realitäten zu erschaffen\\n\\n](/knowledge/ki-und-ihr-potenzial-neue-realitaeten-zu-erschaffen)\\n\\n[Beitrag](/knowledge/category:Beitrag) [Künstliche Intelligenz\\n(KI)](/knowledge/tag:Künstliche Intelligenz \\\\(KI\\\\))\\n\\n[ ](/knowledge/ki-facebook-leak-open-source-community-fordert-tech-konzerne-\\nheraus)\\n\\n[ KI-Facebook-Leak\\n\\n##  Open-Source Community fordert Tech-Konzerne heraus\\n\\n](/knowledge/ki-facebook-leak-open-source-community-fordert-tech-konzerne-\\nheraus)\\n\\n[Beitrag](/knowledge/category:Beitrag) [Künstliche Intelligenz\\n(KI)](/knowledge/tag:Künstliche Intelligenz \\\\(KI\\\\))\\n\\n[ Noch mehr... ](/knowledge)\\n\\n**Deepshore GmbH**  \\nVan-der-Smissen-Straße 9, 22767 Hamburg  \\nTel +49 40 46664 296\\n\\n[Impressum](/de/company/contact-imprint-privacy) |\\n[Kontakt](/de/company/contact-imprint-privacy) |\\n[Datenschutzerklärung](/de/company/contact-imprint-privacy) |\\n[AGB](/de/company/conditions)\\n\\n', metadata={'Source': 'https://deepshore.de/knowledge/2021-04-08'}),\n",
       " Document(page_content='[ ![Deepshore Logo\\nwhite](/user/themes/deepshore/images/Deepshore_LogoMINI_bis1000px_transparentRGB.svg)\\n![Deepshore\\nLogo](/user/themes/deepshore/images/Deepshore_LogoMINI_bis1000px_RGB.svg) ](/)\\n\\n[ Home ](/) [ Wissen ](/knowledge) [ Unternehmen ](/company) [ Chatbot\\n](/chat) [ Kontakt | Impressum | Datenschutz ](/company/contact-imprint-\\nprivacy) [ __   en ](/en/knowledge/2020-03-09)\\n\\n![](/images/a/d/o/b/e/adobestock313038968ret-rgb-df6f0b59.jpg?g-fe3cd0e1)\\n\\n##\\n\\n###  BELEGAUSGABEPFLICHT ZUR VERMEIDUNG VON STEUERBETRUG – ÜBER SINN, UNSINN\\nUND DIE REALITÄT\\n\\n9\\\\. March 2020 \\\\-  Falk Borgmann\\n\\n[Beitrag](/knowledge/category:Beitrag) [Recht und\\nCompliance](/knowledge/tag:Recht und Compliance)\\n[Kassendaten](/knowledge/tag:Kassendaten)\\n\\nDem Steuerbetrug den Kampf ansagen – so lautet das Motto. Und die Aufregung\\nist jetzt groß. Seit diesem Jahr gilt in Deutschland eine Belegausgabepflicht,\\ndie verbindlich vorschreibt, dass ein Händler oder Verkäufer seinem Kunden ein\\nKassenbeleg überlassen muss, mit dem der Kunde dann machen kann, was er will.\\nTonnen an Thermopapier werden nun verbraucht, das meistens direkt im Mülleimer\\nlandet. Nein, nicht einmal im Altpapier, selbst wenn es „Papier“ heißt und\\nauch dann nicht, wenn bei der Herstellung auf den Stoff Bisphenol A verzichtet\\nwurde. In den meisten Fällen ist es einfach Restmüll.\\n\\nÜberrascht wurde der Handel nun von dem 2016 verabschiedeten „Gesetz zum\\nSchutz vor Manipulationen an digitalen Grundaufzeichnungen“ (GSMdG) und der\\ndazugehörigen Kassensicherungsverordnung (KassenSichV, 2017) und geht jetzt\\ngegen die Papierverschwendung in die Offensive. Wer denkt: „Wir haben doch\\n2020? Dann ist das Gesetz doch schon über drei Jahre alt?“, der hat vollkommen\\nrecht. Die Ausgabepflicht ist daher auch nicht isoliert zu betrachten, sondern\\nimmer im Gesamtkontext bestehender und neuer Regelungen. Um den Sinn und\\nUnsinn des öffentlichen Diskurses einmal etwas zu ordnen, habe ich die\\nHintergründe für den Laien im folgenden Beitrag etwas sortiert.\\n\\nWer hat an der Uhr gedreht?  \\nSo richtig nahm das Thema „Steuerbetrug im Kassendatenkontext“ im Jahr 2003\\nmit einem Bericht des Bundesrechnungshofes Fahrt auf. Von Steuerausfällen in\\nMilliardenhöhe war hier die Rede. Damals wurde das INSIKA-Verfahren (INSIKA –\\nIntegrierte Sicherheitslösung für messwertverarbeitende Kassensysteme)\\nzusammen mit mehreren Partnern entwickelt. Es sollte die angemahnten möglichen\\nManipulationen an den Kassen verhindern. Geplant war, die rechtlichen\\nGrundlagen zur Einführung von INSIKA im Jahr 2008 zu schaffen. Daraus wurde\\njedoch nichts. Vielmehr wurde dem Wunsch des Handels nachgegeben, nicht ein\\nkonkretes Verfahren oder eine bestimmte Technologie vorzuschreiben – zu teuer\\nund zu unflexibel, so die Argumentation. Stattdessen stand am Ende in den\\nbeiden zuvor genannten Verordnungen, eine neutral formulierte Variante im\\nGesetzestext, die sich ausschließlich auf das gewünschte technische Verhalten\\nkonzentrierte und dabei insbesondere zwei Dinge fokussierte: Zum einen handelt\\nes sich um eine sogenannte TSE (Technische Sicherheitseinrichtung), die jeden\\nKassenbeleg technisch signieren muss und es so unmöglich machen soll,\\ninnerhalb eines Einzelbelegs zu manipulieren oder gar ganze Belege\\nverschwinden zu lassen. Zum anderen gibt es die als DSFinV-K (Digitale\\nSchnittstelle der Finanzverwaltung für Kassensysteme) bekannte\\nDatenüberlassung, mit der ein Steuerprüfer Kassendaten bis auf\\nEinzelpositionsebene prüfen kann. Der Handel hatte also gewonnen und man\\nkonnte sich auch die teure Umrüstung seiner Kassen mit Smart Cards sparen. Auf\\nden ersten Blick ein Sieg für die Freiheit.\\n\\nManchmal kommt es anders  \\nAber eines wurde von den Akteuren nicht ganz bis zu Ende gedacht, denn ohne\\neine konkrete Vorgabe konnte es keinen fest definierten Standard geben,\\nsondern lediglich einen technischen Rahmen. Oder anders ausgedrückt: Nun war\\nes an den Kassenherstellern und Handelsunternehmen, diesen Standard je nach\\nLösung ganz individuell zu definieren. Volkswirtschaftlich sicherlich nicht\\nder sinnvollste Ansatz – aber immerhin fast technologieoffen. Der Staat, der\\nbei INSIKA die Ausgabe der Smart Card quasi organisiert und somit auch die\\nFunktion der jeweiligen Lösung ein Stück weit mit verantwortet hätte, ist nun\\nfein raus. Das Bundesministerium für Finanzen (BMF) hat gesagt, was das\\nErgebnis sein muss und jeder Händler oder Kassenhersteller kann es\\nrealisieren, wie er lustig ist – solange man sich an die technischen Vorgaben\\ndes Bundesamtes für Sicherheit in der Informationstechnik (BSI) hält und einen\\nPrüfer von der rechtlichen Sinnhaftigkeit der individuellen Gesamtlösung\\nüberzeugen kann.\\n\\nGoBD (2014 – Neufassung 2019) und Aufbewahren digitaler Unterlagen bei\\nBargeschäften (BMF-Schreiben von 2010)  \\nWas bei der Diskussion häufig vollständig verdrängt wird, ist die Tatsache,\\ndass die GoBD (Grundsätze zur ordnungsmäßigen Führung und Aufbewahrung von\\nBüchern, Aufzeichnungen und Unterlagen in elektronischer Form sowie zum\\nDatenzugriff) und das o. g. Schreiben des BMF von 2010 auch noch gültig sind.\\nEs ist sogar sehr wichtig, zukünftige Lösungen nicht nur im Lichte neuer\\nRegularien, sondern im Kontext der bereits bestehenden rechtlichen\\nRahmenbedingungen zu bewerten. GoBD und das BMF-Schreiben von 2010 regeln\\ngewissermaßen all das, was mit einem Kassenbeleg oder einem TSE-\\nTransaktionsprotokoll passieren muss, wenn diese produziert wurden und das\\nQuellsystem verlassen haben. Dass diese Daten ein Quellsystem verlassen\\nsollten, liegt zumindest bei größeren Handelsunternehmen mit mehreren\\nKassensystemen und einer zentralen IT auf der Hand. Denn die\\nAufbewahrungsfrist von zehn Jahren übersteigt die durchschnittliche\\nLebenserwartung einer Kassenhardware und einer USB-basierten TSE. Von daher\\nist es zwingend erforderlich, diese Daten in einem Archivsystem zu verwahren.\\nAußerdem müssen die entsprechenden Informationen für eine zentrale\\nSteuerprüfung greifbar sein, was mit einer dezentralen Datenhaltung nicht\\nsinnvoll umsetzbar ist.\\n\\nVor den Regularien der Fiskalisierung war die Lücke aus Sicht des BMF das\\nKassensystem selbst, denn es gab keine genaue Definition, was die\\nOriginaldaten des Kassensystems sind (lokaler Kassenschieber, lokaler Server,\\nzentraler Kassenserver), respektive, wie innerhalb eines Kassensystems\\nsichergestellt werden muss, dass alle Transaktionen korrekt erfasst und\\nverarbeitet wurden. Andere EU-Länder sind schon lange einen Schritt weiter und\\nhaben diesen Bereich auch von rechtlicher Seite mit genauen Vorgaben\\nunterfüttert. Mithilfe von spezieller Software wie „Zapper“, konnten in\\nDeutschland Kassensysteme relativ einfach manipuliert werden. Unter Zappern\\nversteht der Gesetzgeber jene Art von Software, die nur vorübergehend für die\\nManipulation von Daten in das Kassensystem geladen wird und keine direkten\\nSpuren hinterlässt. Sie kann gespeicherte Transaktions- und Umsatzdaten\\nnachträglich verändern oder ganz löschen. Mit dieser Software kann am\\nKassensystem selbst manipuliert werden, auch wenn der folgende Gesamtprozess\\nim Sinne der GoBD sowie des BMF-Schreibens von 2010 vollständig und\\ntransparent realisiert wurde. Diese Lücke wurde durch die Kombination von TSE\\nund DSFinV-K geschlossen. Somit bilden GoBD, BMF-Schreiben 2010, KassenSichV\\nund GSMdG und alle zugehörigen Ergänzungen (z. B. DSFinV-K, §146a AO und\\ntechnische Richtlinien des BSI) ein gesamtheitliches Konstrukt, das den Rahmen\\neiner Kasseninfrastruktur definiert. Dazu gehören also:\\n\\nKassensoftware,  \\nTechnische Sicherheitseinrichtung (TSE),  \\nangeschlossenes Langzeitarchiv,  \\ndatenlogistische Prozesse (Datenentsorgung aus der Kasse/TSE),  \\nDSFinV-K-Download und  \\nVerfahrensdokumentation.  \\nSich als Händler dabei auf den Kassenhersteller zu verlassen bzw. zu glauben,\\ndass mit der Einbindung einer TSE alles erledigt sei, ist grob fahrlässig und\\nkann im Zweifel sehr teuer werden.\\n\\nZiele einer Prüfung ab Oktober 2020  \\nAuf Basis der skizzierten Gesetze und Verordnungen und den sich daraus\\nableitenden weitreichenden Prüfungsmöglichkeiten ist ein Steuerprüfer in der\\nLage, sich ein relativ umfassendes und vollständiges Bild über die\\n(Kassen-)Daten eines Händlers zu verschaffen. Über die bereits erwähnte\\nDatenüberlassung (DSFinV-K) kann schnell die Vollständigkeit der Belege\\nüberprüft werden. Zusammen mit den Transaktionsdaten einer TSE, die das\\nErstellen jedes einzelnen Belegs speichert, hat der Prüfer ein mächtiges und\\nschwer zu manipulierendes Werkzeug zur Hand. Und entgegen der verbreiteten\\nAuffassung, dass die DSFinV-K nur bei einer Außenprüfung (einer sogenannten\\nKassennachschau) relevant ist (und deshalb nur Stichproben auf\\nEinzelkassenebene durchgeführt werden können), wird sich eine Prüfung mit\\nhoher Wahrscheinlichkeit nun auf die zentralen IT-Systeme ausweiten. Denn\\nwarum sollte ein Prüfer auf dieses Instrument bei einer zentralen\\nSteuerprüfung verzichten? Einen DSFinV-K-Download im Rahmen einer zentralen\\nSteuerprüfung zu fordern, ist rechtlich keinesfalls ausgeschlossen – ganz im\\nGegenteil. Als explizites Ziel der DSFinV-K sind „die Auslagerung von Daten in\\nein Archivsystem“ und die „vereinfachte Überprüfung von Daten der\\nFinanzbuchhaltung auf Basis von Kassendaten“ definiert. Das bedeutet so viel\\nwie: Eine DSFinV-K-Datenüberlassung aus einem zentralen Sicherungssystem\\n(Archiv) zum Abgleich mit der Finanzbuchhaltung wird sehr wahrscheinlich\\nkommen. Hier wird klar, dass die bisher häufig übliche Datenüberlassung (Z3-\\nim alten IDEA-Format) auf Basis der Finanzbuchhaltung im Fall von Kassendaten\\nobsolet wird. Es sei denn, man kann seinen Steuerprüfer davon überzeugen, dass\\nes sinnvoll ist, die Daten der FiBu anhand eines Datenextraktes aus eben\\ndieser FiBu zu validieren.\\n\\nkassendaten belegpflicht\\n\\nDie Haltung des Handels in dieser Sache ist sehr unterschiedlich. Einige\\nHändler bereiten sich seit Monaten akribisch auf die Zukunft vor und einige\\nsind Meister darin, den Kopf in den Sand zu stecken. „Man kann doch nicht\\nerwarten, dass die Buchungen in der Finanzbuchhaltung mit den Rohdaten aus der\\nKasse vergleichbar sind“, so ein Verantwortlicher eines Handelskonzerns. Ich\\nbin mir nicht sicher, inwieweit ein Finanzbeamter dieser Argumentation im\\nFalle von Auffälligkeiten im Rahmen einer Prüfung folgen wird. Ich halte es\\nfür wahrscheinlicher, dass der Fiskus ein gesteigertes Interesse daran hat,\\nsich entsprechende Strafzahlungen nicht entgehen zu lassen. Auf jeden Fall\\ngibt es ab Oktober 2020 kaum noch die Möglichkeit, Daten innerhalb eines\\nKassensystems zu manipulieren.\\n\\nBleibt die Frage, welchen Beitrag die Belegausgabepflicht liefert, um\\nSteuerbetrug zu vermeiden? Klare und kurze Antwort: keinen.\\n\\nTeilen\\n\\n__\\n\\nLink in Zwischenablage kopiert.\\n\\nMehr\\n\\n[ ](/knowledge/2023-05-08)\\n\\n[ Mit standard Framework\\n\\n##  Loadtesting als Day-2-Operations von Container Lösungen\\n\\n](/knowledge/2023-05-08)\\n\\n[Beitrag](/knowledge/category:Beitrag) [Kubernetes](/knowledge/tag:Kubernetes)\\n[Deployment](/knowledge/tag:Deployment) [Open-Source](/knowledge/tag:Open-\\nSource)\\n\\n[ ](/knowledge/ki-und-ihr-potenzial-neue-realitaeten-zu-erschaffen)\\n\\n[\\n\\n##  KI und ihr Potenzial, neue Realitäten zu erschaffen\\n\\n](/knowledge/ki-und-ihr-potenzial-neue-realitaeten-zu-erschaffen)\\n\\n[Beitrag](/knowledge/category:Beitrag) [Künstliche Intelligenz\\n(KI)](/knowledge/tag:Künstliche Intelligenz \\\\(KI\\\\))\\n\\n[ ](/knowledge/ki-facebook-leak-open-source-community-fordert-tech-konzerne-\\nheraus)\\n\\n[ KI-Facebook-Leak\\n\\n##  Open-Source Community fordert Tech-Konzerne heraus\\n\\n](/knowledge/ki-facebook-leak-open-source-community-fordert-tech-konzerne-\\nheraus)\\n\\n[Beitrag](/knowledge/category:Beitrag) [Künstliche Intelligenz\\n(KI)](/knowledge/tag:Künstliche Intelligenz \\\\(KI\\\\))\\n\\n[ Noch mehr... ](/knowledge)\\n\\n**Deepshore GmbH**  \\nVan-der-Smissen-Straße 9, 22767 Hamburg  \\nTel +49 40 46664 296\\n\\n[Impressum](/de/company/contact-imprint-privacy) |\\n[Kontakt](/de/company/contact-imprint-privacy) |\\n[Datenschutzerklärung](/de/company/contact-imprint-privacy) |\\n[AGB](/de/company/conditions)\\n\\n', metadata={'Source': 'https://deepshore.de/knowledge/2020-03-09'})]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectordb.as_retriever()\n",
    "\n",
    "retriever.get_relevant_documents(\"Advent\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
